sim_time_ms: 300000
seed: 123
verbose: false
debug: false
execution_mode: blocking
gamma: 12
prompt_length_min: 24
prompt_length_max: 512
prompt_scale_by_capability: true
answer_length_mean: 140
answer_length_std: 35
answer_length_min: 60
answer_length_max: 220
use_answer_distribution: true
mixed_batching: true
router: jsq
global_router: disabled
workload:
  arrival: poisson
  rate_rps: 220.0
think_time:
  enabled: false
  distribution: lognormal
  mean_ms: 1700
  cv: 0.6
  min_ms: 220
performance_model:
  type: vidur
  vidur:
    table_path: null
    bootstrap_defaults: false
    realtime_enabled: true
    realtime_cache_dir: data/vidur/cache
scheduler:
  type: baseline
  pools:
    default:
      clusters:
      - default
  prefill:
    pool: default
    queue_policy: priority
    max_batch_requests: 4
    max_wait_ms: 0.55
    max_queue_depth: 16
    backpressure_wait_ms: 0.1
  decode:
    pool: default
    queue_policy: priority
    max_batch_requests: 4
    max_wait_ms: 0.55
    max_queue_depth: 16
    backpressure_wait_ms: 0.1
  kv:
    default_capacity_tokens: 240000
    max_utilization_pct: 85.0
auto_topology:
  clusters:
  - name: default
    router: jsq
    targets:
      count: 6
      tiers:
      - name: dc_prefill
        count: 1
        model: qwen-72b-prefill
        gpu: H100
        weight: 1.0
        batch_window_ms: 0.35
        batch_size: 10
        vidur:
          model_name: Qwen/Qwen-72B
          device: H100
          network_device: H100_DGX
          tensor_parallel: 1
          pipeline_parallel: 1
          scheduler: sarathi
          chunk_size: 512
      - name: dc_decode
        count: 1
        model: llama-2-70b-decode
        gpu: H100
        weight: 0.9
        batch_window_ms: 0.45
        batch_size: 12
        vidur:
          model_name: meta-llama/Llama-2-70b-hf
          device: H100
          network_device: H100_DGX
          tensor_parallel: 1
          pipeline_parallel: 1
          scheduler: sarathi
          chunk_size: 512
      - name: regional_qwen
        count: 1
        model: qwen-72b
        gpu: A100
        weight: 0.8
        batch_window_ms: 0.95
        batch_size: 14
        vidur:
          model_name: Qwen/Qwen-72B
          device: A100
          network_device: A100_DGX
          tensor_parallel: 1
          pipeline_parallel: 1
          scheduler: sarathi
          chunk_size: 512
      - name: regional_llama
        count: 1
        model: llama-2-70b
        gpu: A100
        weight: 0.7
        batch_window_ms: 0.9
        batch_size: 16
        vidur:
          model_name: meta-llama/Llama-2-70b-hf
          device: A100
          network_device: A100_DGX
          tensor_parallel: 1
          pipeline_parallel: 1
          scheduler: sarathi
          chunk_size: 512
      - name: edge_heavy
        count: 1
        model: llama-2-70b
        gpu: A40
        weight: 0.35
        batch_window_ms: 1.9
        batch_size: 6
        vidur:
          model_name: meta-llama/Llama-2-70b-hf
          device: A40
          network_device: A40_PAIRWISE_NVLINK
          tensor_parallel: 1
          pipeline_parallel: 1
          scheduler: sarathi
          chunk_size: 512
      - name: edge_mid
        count: 1
        model: codellama-34b
        gpu: A40
        weight: 0.3
        batch_window_ms: 1.7
        batch_size: 8
        vidur:
          model_name: codellama/CodeLLaMA-34b-Instruct-hf
          device: A40
          network_device: A40_PAIRWISE_NVLINK
          tensor_parallel: 1
          pipeline_parallel: 1
          scheduler: sarathi
          chunk_size: 512
    drafts:
      count: 100
      capability_map:
        rack_ultra: 1.35
        rack_high: 0.95
        regional_mid: 0.65
        edge_low: 0.35
      draft_bucket_labels:
      - rack_ultra
      - rack_high
      - regional_mid
      - edge_low
      reliability:
        rack_ultra: 0.997
        rack_high: 0.992
        regional_mid: 0.982
        edge_low: 0.96
      count_by_label:
        rack_ultra: 40
        rack_high: 30
        regional_mid: 20
        edge_low: 10
      metadata_by_label:
        rack_ultra:
          model: internlm-20b
          gpu: A40
          vidur_profile:
            model_name: internlm/internlm-20b
            device: A40
            network_device: A40_PAIRWISE_NVLINK
            tensor_parallel: 1
            pipeline_parallel: 1
            scheduler: sarathi
            chunk_size: 512
        rack_high:
          model: llama-2-7b
          gpu: A40
          vidur_profile:
            model_name: meta-llama/Llama-2-7b-hf
            device: A40
            network_device: A40_PAIRWISE_NVLINK
            tensor_parallel: 1
            pipeline_parallel: 1
            scheduler: sarathi
            chunk_size: 512
        regional_mid:
          model: codellama-13b
          gpu: A40
          vidur_profile:
            model_name: codellama/CodeLLaMA-34b-Instruct-hf
            device: A40
            network_device: A40_PAIRWISE_NVLINK
            tensor_parallel: 1
            pipeline_parallel: 1
            scheduler: sarathi
            chunk_size: 512
        edge_low:
          model: phi-2
          gpu: A40
          vidur_profile:
            model_name: microsoft/phi-2
            device: A40
            network_device: A40_PAIRWISE_NVLINK
            tensor_parallel: 1
            pipeline_parallel: 1
            scheduler: sarathi
            chunk_size: 512
    connectivity:
      fanout_per_draft: 6
      net_ms_ranges:
        dc_prefill:
        - 1.2
        - 2.5
        dc_decode:
        - 1.5
        - 3.0
        regional_qwen:
        - 5.0
        - 8.0
        regional_llama:
        - 6.0
        - 10.0
        edge_heavy:
        - 15.0
        - 22.0
        edge_mid:
        - 18.0
        - 28.0
      acceptance_by_tier:
        rack_ultra:
          dc_prefill: 0.96
          dc_decode: 0.94
          regional_qwen: 0.92
        rack_high:
          dc_prefill: 0.93
          dc_decode: 0.9
          regional_llama: 0.88
        regional_mid:
          regional_qwen: 0.86
          regional_llama: 0.82
          edge_heavy: 0.78
        edge_low:
          edge_heavy: 0.7
          edge_mid: 0.65
      link_jitter_pct: 0.1
router_params: {}
global_router_params: {}
burn_in_ms: 0
